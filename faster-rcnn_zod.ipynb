{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO data format to RCNN format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.image_folder = os.path.join(root, \"images\")\n",
    "        self.label_folder = os.path.join(root, \"labels\")\n",
    "\n",
    "        # Create a list of image paths and corresponding label paths\n",
    "        self.images = [f for f in os.listdir(self.image_folder) if f.endswith('.jpg')]\n",
    "        self.labels = [f for f in os.listdir(self.label_folder) if f.endswith('.txt')]\n",
    "\n",
    "        # Mapping images with their corresponding labels\n",
    "        self.image_label_pairs = [\n",
    "            (img, lbl) for img in self.images for lbl in self.labels\n",
    "            if os.path.splitext(img)[0] == os.path.splitext(lbl)[0]\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, label_name = self.image_label_pairs[idx]\n",
    "        img_path = os.path.join(self.image_folder, img_name)\n",
    "        label_path = os.path.join(self.label_folder, label_name)\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_width, img_height = img.size\n",
    "\n",
    "        # Load bounding boxes and labels\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                elements = line.strip().split()\n",
    "                label = int(elements[0])\n",
    "                x_center, y_center, width, height = map(float, elements[1:])\n",
    "                \n",
    "                # Convert normalized values to pixel coordinates\n",
    "                x_min = (x_center - width / 2) * img_width\n",
    "                y_min = (y_center - height / 2) * img_height\n",
    "                x_max = (x_center + width / 2) * img_width\n",
    "                y_max = (y_center + height / 2) * img_height\n",
    "                \n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(label)\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target = {\"boxes\": boxes, \"labels\": labels}\n",
    "\n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_label_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Set up the dataset and data loader\n",
    "    dataset = CustomDataset(root=\"dataset_zod/test\", transforms=F.to_tensor)\n",
    "    data_loader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "    # Load a pre-trained Faster R-CNN model and modify it for your number of classes\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    num_classes = 11  # Update this with your actual number of classes (background included)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # Define optimizer and learning rate\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for images, targets in data_loader:\n",
    "            images = list(image.to(device) for image in images)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            i += 1\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Iteration {i}, Loss: {losses.item()}\")\n",
    "\n",
    "    print(\"Training completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 000021_india_2021-04-15T12:59:51.662875Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000021_india_2021-04-15T12:59:51.662875Z.jpg\n",
      "Processed 000051_golf_2021-04-29T05:38:42.111236Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000051_golf_2021-04-29T05:38:42.111236Z.jpg\n",
      "Processed 000055_india_2021-04-14T11:35:43.225463Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000055_india_2021-04-14T11:35:43.225463Z.jpg\n",
      "Processed 000089_india_2021-04-18T15:55:46.776483Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000089_india_2021-04-18T15:55:46.776483Z.jpg\n",
      "Processed 000096_india_2021-04-19T10:48:43.670665Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000096_india_2021-04-19T10:48:43.670665Z.jpg\n",
      "Processed 000228_india_2021-04-19T08:36:12.774650Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000228_india_2021-04-19T08:36:12.774650Z.jpg\n",
      "Processed 000254_india_2021-04-19T09:48:26.776189Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000254_india_2021-04-19T09:48:26.776189Z.jpg\n",
      "Processed 000289_india_2021-04-18T16:15:28.002746Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000289_india_2021-04-18T16:15:28.002746Z.jpg\n",
      "Processed 000429_india_2021-04-26T08:12:59.224113Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000429_india_2021-04-26T08:12:59.224113Z.jpg\n",
      "Processed 000474_golf_2021-04-28T20:30:23.329463Z.jpg, saved to /Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results/inference_000474_golf_2021-04-28T20:30:23.329463Z.jpg\n",
      "Inference completed for the first 100 images.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "\n",
    "# Path to the folder containing the images\n",
    "image_folder = \"/Users/varunravi/Desktop/OD/dataset_zod/valid/images\"\n",
    "output_folder = \"/Users/varunravi/Desktop/OD/dataset_zod/valid/inference_results\"  # Save results in a new folder\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Load the trained Faster R-CNN model\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "num_classes = 91  # Your number of classes (including background)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "# Load the model's trained weights\n",
    "# Assuming you have saved your trained model weights as 'model.pth'\n",
    "model.load_state_dict(torch.load('/Users/varunravi/Desktop/OD/fastr-rcnn-trained.pth'))\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Set device\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#model.to(device)\n",
    "\n",
    "# Get the list of images and sort them\n",
    "images = sorted([img for img in os.listdir(image_folder) if img.endswith('.jpg')])[:10]\n",
    "\n",
    "# Perform inference on the first 100 images\n",
    "for img_name in images:\n",
    "    img_path = os.path.join(image_folder, img_name)\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "    image_tensor = F.to_tensor(image).unsqueeze(0)  # Add batch dimension and send to device\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image_tensor)\n",
    "\n",
    "    # Extract predictions\n",
    "    pred_boxes = predictions[0]['boxes'].cpu().numpy()  # Bounding boxes\n",
    "    pred_scores = predictions[0]['scores'].cpu().numpy()  # Confidence scores\n",
    "    pred_labels = predictions[0]['labels'].cpu().numpy()  # Class labels\n",
    "\n",
    "    # Set a confidence threshold\n",
    "    threshold = 0.01\n",
    "    selected_indices = [i for i, score in enumerate(pred_scores) if score > threshold]\n",
    "\n",
    "    # Draw bounding boxes and labels on the image\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "    for i in selected_indices:\n",
    "        box = pred_boxes[i]\n",
    "        label = pred_labels[i]\n",
    "        score = pred_scores[i]\n",
    "        draw.rectangle(((box[0], box[1]), (box[2], box[3])), outline=\"red\", width=3)\n",
    "        draw.text((box[0], box[1]), f'{label}:{score:.2f}', fill=\"white\", font=font)\n",
    "\n",
    "    # Save the result image\n",
    "    output_path = os.path.join(output_folder, f\"inference_{img_name}\")\n",
    "    image.save(output_path)\n",
    "\n",
    "    print(f\"Processed {img_name}, saved to {output_path}\")\n",
    "\n",
    "print(\"Inference completed for the first 100 images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
